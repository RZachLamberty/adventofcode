{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# day 19\n",
    "\n",
    "https://adventofcode.com/2021/day/19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import logging.config\n",
    "import os\n",
    "\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../logging.yaml') as fp:\n",
    "    logging_config = yaml.load(fp, Loader=yaml.FullLoader)\n",
    "\n",
    "logging.config.dictConfig(logging_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FNAME = os.path.join('data', 'day19.txt')\n",
    "\n",
    "LOGGER = logging.getLogger('day19')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part 1\n",
    "\n",
    "### problem statement:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_data(fname=FNAME):\n",
    "    with open(fname) as fp:\n",
    "        parsed = {}\n",
    "        scanner_blocks = [line.split('\\n')\n",
    "                          for line in fp.read().strip().split('\\n\\n')]\n",
    "        \n",
    "        for scanner_block in scanner_blocks:\n",
    "            scanner_number = int(scanner_block[0].split(' ')[2])\n",
    "            parsed[scanner_number] = np.array([\n",
    "                [int(_) for _ in line.split(',')]\n",
    "                for line in scanner_block[1:]\n",
    "            ])\n",
    "        return parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = load_data('data/day19-test.txt')\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_2d = load_data('data/day19-test-2d.txt')\n",
    "test_data_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdist(test_data_2d[0], 'cityblock')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "def get_pair_distances(d):\n",
    "    return {k: pdist(v, 'cityblock') for (k, v) in d.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_pair_distances(test_data_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def find_overlaps(d, num_for_overlap=12):\n",
    "    pair_dists = get_pair_distances(d)\n",
    "    keys = sorted(pair_dists.keys())\n",
    "    for (k0, k1) in itertools.combinations(keys, 2):\n",
    "        v0 = pair_dists[k0]\n",
    "        v1 = pair_dists[k1]\n",
    "        overlaps = set(v0).intersection(set(v1))\n",
    "        if len(overlaps) >= (num_for_overlap * (num_for_overlap - 1)) / 2:\n",
    "            # calculate the actual directions of the overlapping distances\n",
    "            # determine the transformation to take basis 0 --> basis 1\n",
    "            s0 = squareform(v0)\n",
    "            s1 = squareform(v1)\n",
    "            \n",
    "            # find a distance such that both s0 and s1 have one and only one record\n",
    "            # at that distance\n",
    "            for dist in list(overlaps):\n",
    "                try:\n",
    "                    i00, i01 = np.where(s0 == dist)[0]\n",
    "                    i10, i11 = np.where(s1 == dist)[0]\n",
    "                except ValueError:\n",
    "                    continue\n",
    "            \n",
    "            rec00 = d[k0][i00]\n",
    "            rec01 = d[k0][i01]\n",
    "            delta0 = rec00 - rec01\n",
    "            \n",
    "            rec10 = d[k1][i10]\n",
    "            rec11 = d[k1][i11]\n",
    "            delta1 = rec10 - rec11\n",
    "            \n",
    "            yield k0, k1, overlaps, ((rec00, rec01, delta0), (rec10, rec11, delta1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(find_overlaps(test_data_2d, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(k0, k1, recs) for (k0, k1, _, recs) in find_overlaps(test_data, 12)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_dists = get_pair_distances(test_data)\n",
    "keys = sorted(pair_dists.keys())\n",
    "# for (k0, k1) in itertools.combinations(keys, 2):\n",
    "#     break\n",
    "k0, k1 = 2, 4\n",
    "v0 = pair_dists[k0]\n",
    "v1 = pair_dists[k1]\n",
    "overlaps = set(v0).intersection(set(v1))\n",
    "\n",
    "d = list(overlaps)[0]\n",
    "s0 = squareform(v0)\n",
    "s1 = squareform(v1)\n",
    "\n",
    "np.where(s0 == d)\n",
    "# i0, j0 = np.where(s0 == d)[0]\n",
    "# i1, j1 = np.where(s1 == d)[0]\n",
    "\n",
    "# (i0, j0), (i1, j1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(v0 == list(overlaps)[0]).argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### function def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_1(data):\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_q_1():\n",
    "    LOGGER.setLevel(logging.DEBUG)\n",
    "    assert q_1(test_data) == True\n",
    "    LOGGER.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_q_1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_1(load_data())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part 2\n",
    "\n",
    "### problem statement:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### function def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_2(data):\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_q_2():\n",
    "    LOGGER.setLevel(logging.DEBUG)\n",
    "    assert q_2(test_data) == True\n",
    "    LOGGER.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_q_2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "q_2(load_data())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/day19.txt') as f:\n",
    "    ll = [x for x in f.read().strip().split('\\n\\n')]\n",
    "\n",
    "ll = [[eval(\"[\" + x + \"]\") for x in l.split(\"\\n\")[1:]] for l in ll]\n",
    "\n",
    "coord_remaps = [(0, 1, 2), (0, 2, 1), (1, 0, 2), (1, 2, 0), (2, 0, 1), (2, 1, 0)]\n",
    "coord_negations = [(1, 1, 1), (1, 1, -1), (1, -1, 1), (1, -1, -1), (-1, 1, 1), (-1, 1, -1), (-1, -1, 1), (-1, -1, -1)]\n",
    "def apply(remap, negat, scan):\n",
    "    ret = []\n",
    "    for item in scan:\n",
    "        ret.append([negat[0]*item[remap[0]], negat[1]*item[remap[1]], negat[2]*item[remap[2]]])\n",
    "    return ret\n",
    "\n",
    "distances_from_scan_0 = [(0,0,0)]\n",
    "def find_alignment(scan_a, scan_b):\n",
    "    in_a = set([tuple(x) for x in scan_a])\n",
    "    for remap in coord_remaps:\n",
    "        for negat in coord_negations:\n",
    "            a = scan_a\n",
    "            b = apply(remap, negat, scan_b)\n",
    "            for a_pos in a:\n",
    "                for b_pos in b:\n",
    "                    remap_by = [b_pos[0]-a_pos[0], b_pos[1]-a_pos[1], b_pos[2]-a_pos[2]]\n",
    "                    matches = 0\n",
    "                    all_remapped = []\n",
    "                    for other_b in b:\n",
    "                        remapped_to_a = (other_b[0]-remap_by[0], other_b[1]-remap_by[1], other_b[2]-remap_by[2])\n",
    "                        if remapped_to_a in in_a:\n",
    "                            matches += 1\n",
    "                        all_remapped.append(list(remapped_to_a))\n",
    "                    if matches >= 12:\n",
    "                        print(\"match\", remap_by)\n",
    "                        distances_from_scan_0.append(tuple(remap_by))\n",
    "                        return (True, all_remapped)\n",
    "    return (False, None)\n",
    "\n",
    "good = ll[0]\n",
    "aligned_indices = set()\n",
    "aligned_indices.add(0)\n",
    "aligned = {}\n",
    "aligned[0] = ll[0]\n",
    "all_aligned = []\n",
    "all_aligned += [tuple(x) for x in ll[0]]\n",
    "noalign = set()\n",
    "while len(aligned_indices) < len(ll):\n",
    "    for i in range(len(ll)):\n",
    "        if i in aligned_indices:\n",
    "            continue\n",
    "        for j in aligned_indices:\n",
    "            print(\"Checking\", i, \"against\", j)\n",
    "            if (i,j) in noalign:\n",
    "                continue\n",
    "            ok, remap = find_alignment(aligned[j], ll[i])\n",
    "            if ok:\n",
    "                aligned_indices.add(i)\n",
    "                aligned[i] = remap\n",
    "                all_aligned += [tuple(x) for x in remap]\n",
    "                break\n",
    "            noalign.add((i,j))\n",
    "print(len(set(all_aligned)))\n",
    "\n",
    "dists = []\n",
    "for a in distances_from_scan_0:\n",
    "    for b in distances_from_scan_0:\n",
    "        dists.append(sum([abs(a[0]-b[0]), abs(a[1]-b[1]), abs(a[2]-b[2])]))\n",
    "print(max(dists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

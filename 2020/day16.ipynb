{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# day 16\n",
    "\n",
    "https://adventofcode.com/2020/day/16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import logging.config\n",
    "import os\n",
    "\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../logging.yaml') as fp:\n",
    "    logging_config = yaml.load(fp, Loader=yaml.FullLoader)\n",
    "\n",
    "logging.config.dictConfig(logging_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FNAME = os.path.join('data', 'day16.txt')\n",
    "\n",
    "LOGGER = logging.getLogger('day16')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part 1\n",
    "\n",
    "### problem statement:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = \"\"\"class: 1-3 or 5-7\n",
    "row: 6-11 or 33-44\n",
    "seat: 13-40 or 45-50\n",
    "\n",
    "your ticket:\n",
    "7,1,14\n",
    "\n",
    "nearby tickets:\n",
    "7,3,47\n",
    "40,4,50\n",
    "55,2,20\n",
    "38,6,12\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(fname=FNAME):\n",
    "    with open(fname) as fp:\n",
    "        return fp.read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def parse_data(data):\n",
    "    field_info, my_ticket, nearby_tickets = data.split('\\n\\n')\n",
    "    field_info = [re.match('([\\w ]+): (\\d+)\\-(\\d+) or (\\d+)\\-(\\d+)', line.strip()).groups()\n",
    "                  for line in field_info.split('\\n')\n",
    "                  if line]\n",
    "    field_info = {field: [[int(x0), int(x1)], [int(y0), int(y1)]]\n",
    "                  for (field, x0, x1, y0, y1) in field_info}\n",
    "    my_ticket = [int(_) for _ in my_ticket.split('\\n')[1].split(',')]\n",
    "    nearby_tickets = [[int(_) for _ in ticket.split(',')]\n",
    "                      for ticket in nearby_tickets.split('\\n')[1:]]\n",
    "    nearby_tickets = np.array(nearby_tickets)\n",
    "    return (field_info,\n",
    "            my_ticket,\n",
    "            nearby_tickets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_data(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### function def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "fi, mt, nt = parse_data(test_data)\n",
    "c = collections.Counter(nt.flatten().tolist())\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_1(data):\n",
    "    fi, mt, nt = parse_data(data)\n",
    "    ticket_vals = collections.Counter(nt.flatten().tolist())\n",
    "    allowed_vals = set()\n",
    "    for (f, ((x0, x1), (y0, y1))) in fi.items():\n",
    "        for i in range(x0, x1 + 1):\n",
    "            allowed_vals.add(i)\n",
    "        for j in range(y0, y1 + 1):\n",
    "            allowed_vals.add(j)\n",
    "    return sum(k * v for (k, v) in ticket_vals.items()\n",
    "               if k not in allowed_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_q_1():\n",
    "    LOGGER.setLevel(logging.DEBUG)\n",
    "    assert q_1(test_data) == 71\n",
    "    LOGGER.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_q_1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_1(load_data())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part 2\n",
    "\n",
    "### problem statement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = \"\"\"class: 0-1 or 4-19\n",
    "row: 0-5 or 8-19\n",
    "seat: 0-13 or 16-19\n",
    "\n",
    "your ticket:\n",
    "11,12,13\n",
    "\n",
    "nearby tickets:\n",
    "3,9,18\n",
    "15,1,5\n",
    "5,14,9\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### function def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def q_2(data, is_test=False):\n",
    "    fi, mt, nt = parse_data(data)\n",
    "    ticket_vals = collections.Counter(nt.flatten().tolist())\n",
    "    allowed_vals = set()\n",
    "    for (f, ((x0, x1), (y0, y1))) in fi.items():\n",
    "        for i in range(x0, x1 + 1):\n",
    "            allowed_vals.add(i)\n",
    "        for j in range(y0, y1 + 1):\n",
    "            allowed_vals.add(j)\n",
    "    \n",
    "    unallowed_vals = {k for (k, v) in ticket_vals.items() if k not in allowed_vals}\n",
    "    \n",
    "    # drop bad ones\n",
    "    nt = pd.DataFrame(nt)\n",
    "    nt = nt[~nt.isin(unallowed_vals).any(axis=1)].copy()\n",
    "    \n",
    "    existing_vals = {colname: set(col.unique()) for (colname, col) in nt.items()}\n",
    "    allowed_vals = {f: set() for f in fi}\n",
    "    for (f, ((x0, x1), (y0, y1))) in fi.items():\n",
    "        for i in range(x0, x1 + 1):\n",
    "            allowed_vals[f].add(i)\n",
    "        for j in range(y0, y1 + 1):\n",
    "            allowed_vals[f].add(j)\n",
    "    \n",
    "    field_to_col_idx_map = {}\n",
    "    unassigned_field = set(fi.keys())\n",
    "    \n",
    "    while unassigned_field:\n",
    "        d_f_to_idx = {f: [] for f in allowed_vals if f not in field_to_col_idx_map}\n",
    "        d_idx_to_f = {ci: [] for ci in existing_vals if ci not in field_to_col_idx_map.values()}\n",
    "        \n",
    "        for (field, av) in allowed_vals.items():\n",
    "            if field in field_to_col_idx_map:\n",
    "                continue\n",
    "            for (col_idx, col_vals) in existing_vals.items():\n",
    "                if col_idx in field_to_col_idx_map.values():\n",
    "                    continue\n",
    "                if col_vals.issubset(av):\n",
    "                    d_f_to_idx[field].append(col_idx)\n",
    "                    d_idx_to_f[col_idx].append(field)\n",
    "        \n",
    "        for (field, col_idx_set) in d_f_to_idx.items():\n",
    "            if len(col_idx_set) == 1:\n",
    "                field_to_col_idx_map[field] = col_idx_set[0]\n",
    "                unassigned_field.discard(field)\n",
    "                \n",
    "        for (col_idx, field_set) in d_idx_to_f.items():\n",
    "            if len(field_set) == 1:\n",
    "                field = field_set[0]\n",
    "                field_to_col_idx_map[field] = col_idx\n",
    "                unassigned_field.discard(field)\n",
    "        LOGGER.debug(f\"d_f_to_idx = {d_f_to_idx}\")\n",
    "        LOGGER.debug(f\"d_idx_to_f = {d_idx_to_f}\")\n",
    "        LOGGER.debug(f\"field_to_col_idx_map = {field_to_col_idx_map}\")\n",
    "    \n",
    "    if is_test:\n",
    "        _class = mt[field_to_col_idx_map['class']]\n",
    "        row = mt[field_to_col_idx_map['row']]\n",
    "        seat = mt[field_to_col_idx_map['seat']]\n",
    "        return _class * row * seat\n",
    "    \n",
    "    x = 1\n",
    "    for field, idx in field_to_col_idx_map.items():\n",
    "        if field.startswith('departure'):\n",
    "            x *= mt[idx]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_q_2():\n",
    "    LOGGER.setLevel(logging.DEBUG)\n",
    "    assert q_2(test_data, is_test=True) == 12 * 11 * 13\n",
    "    LOGGER.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_q_2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "q_2(load_data())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fin"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
